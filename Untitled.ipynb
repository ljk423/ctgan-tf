{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:08.502743Z",
     "start_time": "2020-04-11T13:42:02.673359Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:09.442573Z",
     "start_time": "2020-04-11T13:42:08.515228Z"
    }
   },
   "outputs": [],
   "source": [
    "from ctgan.transformer import DataTransformer\n",
    "from ctgan.sampler import Sampler\n",
    "from ctgan.conditional import ConditionalGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:10.412413Z",
     "start_time": "2020-04-11T13:42:09.526927Z"
    }
   },
   "outputs": [],
   "source": [
    "DEMO_URL = 'http://ctgan-data.s3.amazonaws.com/census.csv.gz'\n",
    "train_data = pd.read_csv(DEMO_URL, compression='gzip')\n",
    "discrete_columns = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'income'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:34.331908Z",
     "start_time": "2020-04-11T13:42:10.458597Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbm/.local/share/virtualenvs/ctgan-tf-9J9-GGaM/lib/python3.7/site-packages/sklearn/mixture/_base.py:267: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/home/pbm/.local/share/virtualenvs/ctgan-tf-9J9-GGaM/lib/python3.7/site-packages/sklearn/mixture/_base.py:267: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/home/pbm/.local/share/virtualenvs/ctgan-tf-9J9-GGaM/lib/python3.7/site-packages/sklearn/mixture/_base.py:267: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/home/pbm/.local/share/virtualenvs/ctgan-tf-9J9-GGaM/lib/python3.7/site-packages/sklearn/mixture/_base.py:267: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/home/pbm/.local/share/virtualenvs/ctgan-tf-9J9-GGaM/lib/python3.7/site-packages/sklearn/mixture/_base.py:267: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n",
      "/home/pbm/.local/share/virtualenvs/ctgan-tf-9J9-GGaM/lib/python3.7/site-packages/sklearn/mixture/_base.py:267: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer()\n",
    "transformer.fit(train_data, discrete_columns)\n",
    "train_data = transformer.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:34.524311Z",
     "start_time": "2020-04-11T13:42:34.341657Z"
    }
   },
   "outputs": [],
   "source": [
    "data_sampler = Sampler(train_data, transformer.output_info)\n",
    "data_dim = transformer.output_dimensions\n",
    "cond_generator = ConditionalGenerator(\n",
    "    train_data, transformer.output_info, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:34.560838Z",
     "start_time": "2020-04-11T13:42:34.538889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 + cond_generator.n_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:42:34.587148Z",
     "start_time": "2020-04-11T13:42:34.581795Z"
    }
   },
   "outputs": [],
   "source": [
    "l2scale = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenActLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, num_outputs, transformer_info, tau):\n",
    "        super(GenActLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.transformer_info = transformer_info\n",
    "        self.tau = tau\n",
    "        self.fc = tf.keras.layers.Dense(\n",
    "            num_outputs, input_dim=(input_dim,),\n",
    "            kernel_initializer=partial(init_bounded, dim=input_dim),\n",
    "            bias_initializer=partial(init_bounded, dim=input_dim))\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        outputs = self.fc(inputs, **kwargs)\n",
    "        shape = outputs.shape\n",
    "        #print(shape)\n",
    "        tf.print(shape)\n",
    "        data_t = tf.zeros(shape)\n",
    "        #print(self.transformer_info[0])\n",
    "        x = tf.constant([[2, 3]], dtype=tf.int32)\n",
    "        #print(x)\n",
    "        for idx in self.transformer_info[0]:\n",
    "            #r = tf.range(x[0], idx[1])\n",
    "            #print(r)\n",
    "            #print(tf.gather(data_t, idx, axis=1))\n",
    "            #print(\"Gather:\", tf.gather(data_t, idx, axis=1))\n",
    "            #print(\"Idx:\", idx)\n",
    "            #print(\"Indexing:\", data_t[:, :idx[0]])\n",
    "            tf.print(data_t)\n",
    "            act = tf.where(idx[5] == 0, \n",
    "                           tf.math.tanh(outputs[:,idx[0]:idx[1]]), \n",
    "                           self._gumbel_softmax(outputs[:, idx[0]:idx[1]], tau=self.tau))\n",
    "            #print(\"act:\", act)\n",
    "            data_t = tf.concat([data_t[:,:idx[0]],\n",
    "                                act,\n",
    "                                data_t[:,idx[1]:]],\n",
    "                               axis=1)\n",
    "            tf.print(data_t)\n",
    "            \n",
    "        #print(data_t)\n",
    "        return outputs, data_t\n",
    "    \n",
    "    @tf.function\n",
    "    def _activation(self, data_info, data):\n",
    "        return tf.where(data_info[5] == 0,\n",
    "                  tf.math.tanh(data[:, data_info[0]:data_info[1]]),\n",
    "                  self._gumbel_softmax(data[:, data_info[0]:data_info[1]], tau=self.tau))\n",
    "\n",
    "    @tf.function\n",
    "    def _gumbel_softmax(self, logits, tau=1.0, hard=False, dim=-1):\n",
    "        r\"\"\"\n",
    "        Samples from the Gumbel-Softmax distribution (`Link 1`_  `Link 2`_) and optionally discretizes.\n",
    "\n",
    "        Args:\n",
    "          logits: `[..., num_features]` unnormalized log probabilities\n",
    "          tau: non-negative scalar temperature\n",
    "          hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n",
    "                but will be differentiated as if it is the soft sample in autograd\n",
    "          dim (int): A dimension along which softmax will be computed. Default: -1.\n",
    "\n",
    "        Returns:\n",
    "          Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n",
    "          If ``hard=True``, the returned samples will be one-hot, otherwise they will\n",
    "          be probability distributions that sum to 1 across `dim`.\n",
    "\n",
    "        .. note::\n",
    "          The main trick for `hard` is to do  `y_hard - y_soft.detach() + y_soft`\n",
    "\n",
    "          It achieves two things:\n",
    "          - makes the output value exactly one-hot\n",
    "          (since we add then subtract y_soft value)\n",
    "          - makes the gradient equal to y_soft gradient\n",
    "          (since we strip all other gradients)\n",
    "\n",
    "        .. _Link 1:\n",
    "            https://arxiv.org/abs/1611.00712\n",
    "        .. _Link 2:\n",
    "            https://arxiv.org/abs/1611.01144\n",
    "        \"\"\"\n",
    "\n",
    "        gumbel_dist = tfp.distributions.Gumbel(loc=0, scale=1)\n",
    "        gumbels = gumbel_dist.sample(tf.shape(logits))\n",
    "        gumbels = (logits + gumbels) / tau\n",
    "        y = tf.nn.softmax(gumbels, dim)\n",
    "\n",
    "        if hard:\n",
    "            # Straight through.\n",
    "            index = tf.math.reduce_max(y, 1, keep_dims=True)\n",
    "            y_hard = tf.cast(tf.equal(y, index), y.dtype)\n",
    "            y = tf.stop_gradient(y_hard - y) + y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, input_dim, gen_dims, data_dim, transformer_info, tau):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.model = list()\n",
    "        dim = input_dim\n",
    "        for layer_dim in list(gen_dims):\n",
    "            self.model += [ResidualLayer(dim, layer_dim)]\n",
    "            dim += layer_dim\n",
    "\n",
    "        #self.model += [tf.keras.layers.Dense(\n",
    "        #    data_dim, input_dim=(dim,),\n",
    "        #    kernel_initializer=partial(init_bounded, dim=dim),\n",
    "        #    bias_initializer=partial(init_bounded, dim=dim))]\n",
    "        self.model += [GenActLayer(dim, data_dim, transformer_info, tau)]\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        out = x\n",
    "        for layer in self.model:\n",
    "            out = layer(out, **kwargs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:28.225943Z",
     "start_time": "2020-04-10T14:52:28.218832Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "embedding_dim = z_dim = 128\n",
    "mean = torch.zeros(batch_size, embedding_dim)\n",
    "std = mean + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:43:38.430010Z",
     "start_time": "2020-04-11T13:43:38.412555Z"
    }
   },
   "outputs": [],
   "source": [
    "from ctgan.layers import ResidualLayer, init_bounded\n",
    "from ctgan.models import Critic, Generator\n",
    "from functools import partial\n",
    "generator = Generator(\n",
    "    128 + cond_generator.n_opt, (256,256), data_dim, transformer.output_info_tensor(), 0.2)\n",
    "\n",
    "critic = Critic(data_dim + cond_generator.n_opt, (256,256), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "generator.build((batch_size, generator.input_dim))\n",
    "critic.build((batch_size, critic.input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:46:30.711335Z",
     "start_time": "2020-04-11T13:46:30.705099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ctgan.layers.ResidualLayer at 0x7fc866c3dd90>,\n",
       " <ctgan.layers.ResidualLayer at 0x7fc866dfe6d0>,\n",
       " <__main__.GenActLayer at 0x7fc866c3de90>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:50:16.563504Z",
     "start_time": "2020-04-11T13:50:16.549068Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'residual_layer_2/batch_normalization_2/gamma:0' shape=(256,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1.], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_2/batch_normalization_2/beta:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.layers[0]._layers[1].trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:51:06.865555Z",
     "start_time": "2020-04-11T13:51:06.834663Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'residual_layer_16/dense_48/kernel:0' shape=(232, 256) dtype=float32, numpy=\n",
       " array([[-0.05475991, -0.01095014,  0.05805656, ...,  0.02841506,\n",
       "         -0.03025322, -0.00633234],\n",
       "        [ 0.01443698,  0.01880741, -0.00380489, ..., -0.03929146,\n",
       "         -0.00306889,  0.0562725 ],\n",
       "        [-0.01052445, -0.05357137, -0.06477886, ...,  0.01439786,\n",
       "          0.04665996, -0.06051522],\n",
       "        ...,\n",
       "        [-0.01289388, -0.04914027,  0.05129219, ..., -0.05793067,\n",
       "          0.03870263, -0.00022382],\n",
       "        [-0.04000986, -0.03895237, -0.04620291, ..., -0.00065832,\n",
       "          0.03954718,  0.00330844],\n",
       "        [ 0.01802916, -0.05134067,  0.0075512 , ...,  0.045027  ,\n",
       "         -0.04505192,  0.025952  ]], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_16/dense_48/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([-4.7047235e-02,  4.9967319e-04, -3.6795586e-02, -2.8126828e-02,\n",
       "         2.6086263e-02,  4.8789091e-02, -1.2748964e-02,  3.8183346e-02,\n",
       "        -3.9298117e-02, -7.3188022e-03,  1.1752099e-03,  2.0131446e-02,\n",
       "        -1.7740738e-02, -4.3050393e-02,  4.1855648e-03, -1.3442017e-02,\n",
       "         1.9943267e-02, -1.3865680e-03, -4.1988142e-02,  2.9681481e-02,\n",
       "        -5.2107252e-02,  6.1497673e-02, -3.7239753e-03, -3.2755904e-02,\n",
       "        -1.1287153e-02, -6.5091528e-02, -3.2487143e-02, -1.2929961e-02,\n",
       "         3.2429479e-02,  3.2815136e-02,  5.3323254e-02,  5.0925843e-02,\n",
       "         3.6484390e-02, -5.7777628e-02, -1.0321192e-02,  5.0932840e-03,\n",
       "        -6.4711370e-02,  5.3374656e-02,  3.0075908e-03,  3.3998154e-02,\n",
       "         4.6025835e-02, -1.4560152e-02,  3.3589959e-02,  5.5321746e-02,\n",
       "         4.4889458e-02, -4.9958058e-02, -4.8702881e-03,  2.7665898e-02,\n",
       "         5.5697896e-02, -4.9519055e-02,  1.7764620e-02,  1.9090317e-02,\n",
       "         2.3824871e-03,  3.0215308e-02,  2.0526677e-02, -4.3956529e-02,\n",
       "        -3.1831365e-02, -5.0473209e-02,  3.2777540e-02,  4.3592192e-02,\n",
       "        -9.8450929e-03, -1.3291091e-02, -4.9945630e-02,  5.0045177e-02,\n",
       "        -8.4748045e-03, -9.4980672e-03, -5.1957957e-02, -2.8616413e-03,\n",
       "         5.7732999e-02,  2.4229966e-02,  9.4970986e-03,  4.7407612e-02,\n",
       "        -1.2361087e-02,  2.3895167e-02, -5.7267621e-02, -5.8496285e-02,\n",
       "         5.0448246e-02, -2.6026342e-02,  6.0113892e-03, -3.5684150e-02,\n",
       "        -2.4122633e-02, -5.0728947e-02,  2.4686687e-02, -6.1612677e-02,\n",
       "         5.3998157e-02, -2.0435754e-02,  1.5333362e-02,  7.6364651e-03,\n",
       "         4.9049057e-02, -4.5602560e-02, -2.4839256e-02,  1.6246431e-02,\n",
       "        -3.9947949e-02, -3.4145184e-02, -6.3639626e-02, -3.5436630e-02,\n",
       "        -4.7803883e-02,  6.4203709e-02,  4.8917979e-03, -6.4850636e-03,\n",
       "        -5.6458224e-02, -2.6896052e-02, -4.3325685e-02,  2.6392415e-03,\n",
       "         4.8657939e-02,  2.5619492e-03,  6.0774833e-02,  5.7338029e-03,\n",
       "         6.1670676e-02,  5.5956125e-02, -4.1293241e-03, -4.2438004e-02,\n",
       "        -3.4782805e-02,  7.4098706e-03,  4.0681012e-02, -8.6982027e-03,\n",
       "         1.7411761e-02, -2.9709514e-02, -2.5783677e-02, -4.8138075e-02,\n",
       "        -1.5967399e-02, -2.7893864e-02, -4.5431316e-02, -4.6181828e-02,\n",
       "         1.4482386e-02, -4.4007026e-02, -5.8208756e-02, -3.5268612e-02,\n",
       "         5.6702383e-02, -4.0734105e-02,  5.4860115e-04,  4.8994884e-02,\n",
       "        -1.6310088e-02,  1.4234386e-02, -5.0621912e-02, -5.3624995e-02,\n",
       "         4.9521133e-02,  6.4661190e-02,  2.6068516e-02,  5.6420967e-02,\n",
       "         6.4074099e-03, -5.2344833e-02, -3.3978697e-02,  6.3997924e-02,\n",
       "         3.9807342e-02, -1.7467313e-02,  5.3101107e-02,  3.0644901e-02,\n",
       "         4.3323115e-03,  5.3801343e-02, -3.8485762e-02, -5.7589039e-02,\n",
       "        -1.5213959e-02, -3.1444799e-02, -4.4305764e-02,  7.0189983e-03,\n",
       "         1.8298469e-02,  6.2331691e-02,  1.5425682e-02, -3.5155721e-02,\n",
       "        -4.4519171e-02, -5.1537659e-02,  5.1851362e-02,  5.4909438e-03,\n",
       "        -4.7642719e-02, -5.1929545e-02,  3.6629386e-02, -5.1560666e-02,\n",
       "        -3.1012669e-02, -4.7691539e-02,  6.4393178e-02, -6.0740635e-03,\n",
       "         4.7378056e-02,  8.3389357e-03,  3.7115358e-02, -1.5906807e-02,\n",
       "        -1.4884405e-02, -1.0157902e-02, -6.1395038e-02, -4.4983588e-03,\n",
       "         5.8973953e-02,  8.0831349e-05, -1.8608928e-02,  5.1213406e-02,\n",
       "        -6.1565548e-02,  6.3294157e-02, -1.8003426e-02, -4.5775384e-02,\n",
       "        -6.0330935e-02, -4.5977995e-02,  1.0530800e-03, -3.9556906e-02,\n",
       "         2.1052279e-02, -3.5964243e-02, -5.1644146e-02, -6.3867904e-02,\n",
       "        -1.7409395e-02, -3.5853326e-02, -3.0889306e-02, -3.2429963e-02,\n",
       "         8.4565356e-03,  2.6827447e-02, -1.7539065e-02,  4.4994205e-03,\n",
       "        -9.5320195e-03, -1.4590897e-02, -5.6509614e-02, -3.0115098e-02,\n",
       "        -6.1642420e-02,  2.9815562e-02,  1.3189845e-02, -4.2461000e-02,\n",
       "         2.7469672e-02, -6.2750615e-02,  5.3986982e-02,  5.8620647e-02,\n",
       "        -1.0298669e-02,  1.7549112e-02,  5.4338381e-02,  3.3914477e-02,\n",
       "         2.5260746e-03, -3.6547177e-02, -4.0423378e-02,  4.1444935e-02,\n",
       "        -5.9524309e-02,  2.1514975e-02, -5.6207791e-02, -3.8161367e-02,\n",
       "         5.6941226e-02, -2.9075287e-02,  2.1379925e-02, -1.6911522e-02,\n",
       "         5.9594631e-02, -2.5631484e-02, -3.6777385e-02,  3.7125498e-03,\n",
       "         1.5172325e-02, -1.1361174e-02, -9.8004937e-05, -8.8483766e-03,\n",
       "         4.9197637e-02,  9.4452575e-03,  4.2555295e-02, -2.2732634e-02,\n",
       "         5.6546196e-02, -3.8296282e-02, -1.8684860e-02,  1.6640149e-02,\n",
       "        -5.8770839e-02,  2.3655936e-02,  1.5058339e-02, -4.0841810e-03,\n",
       "         2.0112015e-02, -5.0280899e-02,  2.8503045e-02,  2.7988851e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_16/batch_normalization_16/gamma:0' shape=(256,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1.], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_16/batch_normalization_16/beta:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_17/dense_49/kernel:0' shape=(488, 256) dtype=float32, numpy=\n",
       " array([[ 0.02962077, -0.02763826,  0.01249176, ...,  0.03887943,\n",
       "         -0.03104302,  0.03999145],\n",
       "        [ 0.01935393,  0.02773367,  0.01733288, ...,  0.03869722,\n",
       "         -0.03851525, -0.01735734],\n",
       "        [ 0.04370355, -0.02191411, -0.01654717, ..., -0.02234293,\n",
       "         -0.02775061, -0.04060242],\n",
       "        ...,\n",
       "        [ 0.02175191,  0.02435495,  0.02345928, ...,  0.01310441,\n",
       "         -0.02387142,  0.01861786],\n",
       "        [ 0.01893672,  0.03547832, -0.03082887, ...,  0.03459258,\n",
       "          0.01978834, -0.02026834],\n",
       "        [-0.03981414, -0.03985584,  0.04377252, ..., -0.03349816,\n",
       "          0.00998471,  0.01640217]], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_17/dense_49/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([-0.0110985 ,  0.03453987,  0.00029119,  0.01857515, -0.00458189,\n",
       "        -0.03954297,  0.03758229,  0.03342696, -0.00142548, -0.02016834,\n",
       "         0.00358108, -0.03669813, -0.03456362, -0.0274611 , -0.03848065,\n",
       "         0.03514121,  0.03805327, -0.02542168,  0.01860643, -0.03733651,\n",
       "        -0.00538704,  0.00463919,  0.03379203, -0.00570384, -0.02429962,\n",
       "         0.04078569, -0.02852535,  0.00860585, -0.03722942, -0.01984059,\n",
       "         0.00965865,  0.00818414, -0.00459183,  0.0291727 , -0.00534899,\n",
       "        -0.01776613, -0.02929073,  0.02809041, -0.03870873, -0.02351873,\n",
       "         0.03871029,  0.03758443, -0.03780324,  0.00461481,  0.00202788,\n",
       "        -0.04297334,  0.02461013,  0.03039297, -0.01165803,  0.02523211,\n",
       "         0.00475711, -0.02428192,  0.03226187, -0.00471543, -0.01619285,\n",
       "        -0.02122295, -0.04417854,  0.00200479,  0.01584358, -0.02491412,\n",
       "         0.02428968, -0.03496382, -0.01844506, -0.03635597, -0.00457842,\n",
       "        -0.04471555,  0.00136341, -0.0073119 , -0.01278773, -0.03819806,\n",
       "        -0.01086764, -0.00925003, -0.0361019 , -0.01430263,  0.0358511 ,\n",
       "         0.00401588, -0.00678193,  0.03484473, -0.01880198,  0.02895505,\n",
       "        -0.01720251,  0.01585535,  0.00305342, -0.00680069,  0.01154734,\n",
       "         0.02711856,  0.02744003, -0.02985251, -0.03850117, -0.02220929,\n",
       "         0.03860983, -0.00134254,  0.01288405,  0.01737969, -0.04184191,\n",
       "        -0.03557757, -0.02399569, -0.03324774, -0.01452198,  0.0117592 ,\n",
       "        -0.00315603, -0.03477029,  0.00146348, -0.01894112, -0.00711273,\n",
       "        -0.00211565,  0.02843168, -0.01685064, -0.03097041,  0.04357519,\n",
       "        -0.01095776,  0.03245419, -0.03879071, -0.01307629, -0.00708775,\n",
       "         0.00781745, -0.01764712, -0.00430258,  0.0166739 , -0.01610605,\n",
       "         0.00891778, -0.03623025, -0.03550144,  0.02451791,  0.03740035,\n",
       "        -0.03949462, -0.03598593,  0.01813985, -0.01481892, -0.02989811,\n",
       "         0.00916518, -0.02187941,  0.00099364,  0.01366121, -0.0164173 ,\n",
       "        -0.02674143, -0.04146366,  0.02405304,  0.01208519, -0.0122079 ,\n",
       "         0.00909507,  0.0086218 , -0.02313255, -0.03442557,  0.01296072,\n",
       "        -0.04388463, -0.01348352, -0.04497362, -0.00757994,  0.04414439,\n",
       "         0.04516575, -0.02845154, -0.00463803,  0.01914909, -0.00686876,\n",
       "        -0.03611256, -0.00036167, -0.03851772,  0.0421666 ,  0.02207389,\n",
       "         0.03427554, -0.03454848, -0.00341132,  0.03808039, -0.01132075,\n",
       "        -0.00911499,  0.03095897,  0.02969108, -0.03688325, -0.02999959,\n",
       "         0.03354212, -0.03797146, -0.01823419, -0.04157121,  0.0375318 ,\n",
       "         0.0175745 ,  0.03315734,  0.01687294, -0.00094892, -0.04202124,\n",
       "        -0.01692742, -0.02453353, -0.01989241,  0.01963535,  0.02993353,\n",
       "        -0.01818173, -0.01466313,  0.0268354 , -0.01875018,  0.01915997,\n",
       "         0.00251935,  0.04228161,  0.00696784, -0.01258821, -0.03355887,\n",
       "        -0.00715496,  0.02113727, -0.01685109,  0.00398286, -0.04254249,\n",
       "        -0.01622207,  0.04470915, -0.03200977, -0.00643446, -0.02763174,\n",
       "         0.02366064,  0.02807679,  0.0267814 , -0.02818618, -0.04113103,\n",
       "        -0.00050866, -0.00896484,  0.01968541,  0.01899192, -0.03974162,\n",
       "        -0.03366848,  0.03601617,  0.02341984, -0.02274389,  0.01607071,\n",
       "         0.00948668,  0.00734106,  0.01334941, -0.03816767, -0.01667999,\n",
       "        -0.03122818,  0.01005812,  0.0054788 ,  0.04512542, -0.01581361,\n",
       "         0.04057187, -0.03026989,  0.03258242,  0.03597958,  0.03576701,\n",
       "        -0.00079371, -0.02259608,  0.04479815, -0.00678306, -0.03454585,\n",
       "        -0.04084586,  0.04197372,  0.02027524,  0.01216134, -0.00560753,\n",
       "         0.03569853,  0.00057067,  0.00099736,  0.02372056, -0.03948478,\n",
       "         0.02888279,  0.0148658 ,  0.00119267,  0.00590181,  0.02214173,\n",
       "         0.03457522], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_17/batch_normalization_17/gamma:0' shape=(256,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1.], dtype=float32)>,\n",
       " <tf.Variable 'residual_layer_17/batch_normalization_17/beta:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>,\n",
       " <tf.Variable 'gen_act_layer_8/dense_50/kernel:0' shape=(744, 157) dtype=float32, numpy=\n",
       " array([[ 5.20383939e-03, -2.38660928e-02, -3.38770375e-02, ...,\n",
       "          1.62799284e-03, -1.30076762e-02,  1.49515979e-02],\n",
       "        [ 1.84441544e-02,  2.09540091e-02, -3.63367386e-02, ...,\n",
       "          3.52141373e-02,  3.12031768e-02,  2.60056145e-02],\n",
       "        [ 2.39211954e-02,  3.03995237e-03, -1.76512878e-02, ...,\n",
       "         -1.64084267e-02,  7.46943057e-03, -2.54086517e-02],\n",
       "        ...,\n",
       "        [ 3.43732536e-04,  7.76267052e-03, -1.08441245e-02, ...,\n",
       "         -7.78548419e-05,  2.11737193e-02,  1.65461898e-02],\n",
       "        [-2.70176940e-02, -3.58165279e-02, -2.83137262e-02, ...,\n",
       "          3.16988714e-02,  1.63626410e-02, -2.85300780e-02],\n",
       "        [ 3.17176841e-02,  2.60183550e-02, -3.07628848e-02, ...,\n",
       "         -5.26982173e-03, -1.00219604e-02, -1.52438749e-02]], dtype=float32)>,\n",
       " <tf.Variable 'gen_act_layer_8/dense_50/bias:0' shape=(157,) dtype=float32, numpy=\n",
       " array([-0.02181079,  0.01798114, -0.02626456, -0.03109579, -0.01940632,\n",
       "         0.01759676,  0.00342311, -0.02368779,  0.00846867, -0.00882881,\n",
       "         0.00894847, -0.02049654,  0.02342121, -0.01185779,  0.01609271,\n",
       "        -0.0287581 , -0.03266937, -0.02458497, -0.02395969,  0.03232606,\n",
       "         0.00330837,  0.01131874, -0.02602689,  0.03594798, -0.00810701,\n",
       "        -0.01244672,  0.02986587, -0.00823075,  0.03239525,  0.0217477 ,\n",
       "        -0.03634315,  0.02274955, -0.03514747, -0.01089053, -0.00445517,\n",
       "         0.01770405, -0.01545995,  0.02057556, -0.03614329, -0.02293812,\n",
       "         0.0049137 ,  0.00724799,  0.03052006, -0.02047638, -0.01812883,\n",
       "        -0.02879734,  0.02905549, -0.000879  , -0.02833227,  0.01621703,\n",
       "        -0.0138498 , -0.03572506, -0.01717386, -0.03014554,  0.00689778,\n",
       "         0.01240978, -0.02454099,  0.01775258, -0.01265305, -0.01601044,\n",
       "         0.03646596,  0.02842964,  0.02027673, -0.02831626,  0.00587563,\n",
       "         0.01559186, -0.0206145 ,  0.01720883, -0.0026435 ,  0.00775552,\n",
       "         0.00211062, -0.02896453,  0.00762074, -0.00319558,  0.00785678,\n",
       "         0.03011303,  0.00078459,  0.00336848,  0.0040266 ,  0.01948062,\n",
       "        -0.01446596,  0.01808712,  0.00568985, -0.03402072, -0.00257922,\n",
       "        -0.03289668,  0.01925271, -0.02022554, -0.00347337, -0.00709828,\n",
       "         0.01130977, -0.03564426, -0.00564416,  0.03228692,  0.0296776 ,\n",
       "        -0.01325305, -0.00374496, -0.02036672, -0.01297448, -0.01100484,\n",
       "         0.0295959 ,  0.03627697, -0.00893453,  0.0224468 ,  0.02536631,\n",
       "        -0.01473128,  0.03460136,  0.02689489, -0.00290886,  0.02942014,\n",
       "        -0.01860336, -0.01029078, -0.01508949, -0.02284111, -0.03306314,\n",
       "         0.00432501,  0.02305516, -0.00447595,  0.02793307,  0.02379571,\n",
       "        -0.00238794,  0.01372617, -0.02323624, -0.03534346,  0.01769965,\n",
       "         0.02722463,  0.02762085,  0.00322609,  0.01044771,  0.0200714 ,\n",
       "         0.02225942, -0.00016905,  0.00151467, -0.0363783 ,  0.02144052,\n",
       "        -0.02062781, -0.02511281,  0.0003988 ,  0.02657994,  0.03546343,\n",
       "         0.02830817, -0.00134418, -0.00329454,  0.02356314,  0.03152978,\n",
       "         0.01909058,  0.01363938,  0.02377966,  0.01361165, -0.00965018,\n",
       "        -0.0306057 ,  0.0263734 ,  0.03585374,  0.02438799,  0.0229065 ,\n",
       "         0.03065218,  0.02734034], dtype=float32)>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T13:50:52.790965Z",
     "start_time": "2020-04-11T13:50:52.740285Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DType' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7374fccfde0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-7374fccfde0f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3118\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DType' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "[np.mean(g) for g in generator.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:28.225943Z",
     "start_time": "2020-04-10T14:52:28.218832Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "embedding_dim = z_dim = 128\n",
    "mean = torch.zeros(batch_size, embedding_dim)\n",
    "std = mean + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy weights to TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:31.620240Z",
     "start_time": "2020-04-10T14:52:31.608952Z"
    }
   },
   "outputs": [],
   "source": [
    "critic.layers[1].set_weights([t_critic.seq[0].weight.detach().numpy().T, t_critic.seq[0].bias.detach().numpy()])\n",
    "critic.layers[3].set_weights([t_critic.seq[2].weight.detach().numpy().T, t_critic.seq[2].bias.detach().numpy()])\n",
    "critic.layers[5].set_weights([t_critic.seq[4].weight.detach().numpy().T, t_critic.seq[4].bias.detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:32.286005Z",
     "start_time": "2020-04-10T14:52:32.274027Z"
    }
   },
   "outputs": [],
   "source": [
    "generator.layers[1]._layers[0].set_weights([t_gen.seq[0].fc.weight.detach().numpy().T, t_gen.seq[0].fc.bias.detach().numpy()])\n",
    "generator.layers[2]._layers[0].set_weights([t_gen.seq[1].fc.weight.detach().numpy().T, t_gen.seq[1].fc.bias.detach().numpy()])\n",
    "generator.layers[3].set_weights([t_gen.seq[2].weight.detach().numpy().T, t_gen.seq[2].bias.detach().numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:34.100885Z",
     "start_time": "2020-04-10T14:52:34.084099Z"
    }
   },
   "outputs": [],
   "source": [
    "t_fakez = torch.normal(mean=mean, std=std)\n",
    "tf_fakez = tf.random.normal([batch_size, z_dim])\n",
    "\n",
    "fk = np.random.normal(size=(batch_size, z_dim)).astype(np.float32)\n",
    "t_fakez = torch.from_numpy(fk)\n",
    "tf_fakez = tf.convert_to_tensor(fk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:34.304345Z",
     "start_time": "2020-04-10T14:52:34.287823Z"
    }
   },
   "outputs": [],
   "source": [
    "condvec = cond_generator.sample(batch_size)\n",
    "if condvec is None:\n",
    "    c1, m1, col, opt = None, None, None, None\n",
    "    real = data_sampler.sample(batch_size, col, opt)\n",
    "else:\n",
    "    c1, m1, col, opt = condvec\n",
    "    c1_tf = tf.convert_to_tensor(c1)\n",
    "    m1_tf = tf.convert_to_tensor(m1)\n",
    "    tf_fakez = tf.concat([tf_fakez, c1_tf], axis=1)\n",
    "    \n",
    "    c1_t = torch.from_numpy(c1)\n",
    "    m1_t = torch.from_numpy(m1)\n",
    "    t_fakez = torch.cat([t_fakez, c1_t], dim=1)\n",
    "\n",
    "    perm = np.arange(batch_size)\n",
    "    np.random.shuffle(perm)\n",
    "    real = data_sampler.sample(batch_size, col[perm], opt[perm])\n",
    "    tf_c2 = tf.gather(c1_tf, perm)\n",
    "    t_c2 = c1_t[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:35.020034Z",
     "start_time": "2020-04-10T14:52:34.962417Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function GenActLayer._gumbel_softmax at 0x7f27500df9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "tf_fake = generator(tf_fakez, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:40.282535Z",
     "start_time": "2020-04-10T14:52:40.261877Z"
    }
   },
   "outputs": [],
   "source": [
    "t_fake = t_gen(t_fakez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:44.100043Z",
     "start_time": "2020-04-10T14:52:42.961193Z"
    }
   },
   "outputs": [],
   "source": [
    "from ctgan.layers import _apply_activate\n",
    "tf_fakeact = _apply_activate(tf_fake, transformer.output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:44.262102Z",
     "start_time": "2020-04-10T14:52:44.240810Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional\n",
    "def torch_aa(data, transformer_info):\n",
    "    data_t = []\n",
    "    st = 0\n",
    "    for item in transformer_info:\n",
    "        if item[1] == 'tanh':\n",
    "            ed = st + item[0]\n",
    "            data_t.append(torch.tanh(data[:, st:ed]))\n",
    "            st = ed\n",
    "        elif item[1] == 'softmax':\n",
    "            ed = st + item[0]\n",
    "            data_t.append(functional.gumbel_softmax(data[:, st:ed], tau=0.2))\n",
    "            st = ed\n",
    "        else:\n",
    "            assert 0\n",
    "\n",
    "    return torch.cat(data_t, dim=1)\n",
    "t_fakeact = torch_aa(t_fake, transformer.output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:46.051299Z",
     "start_time": "2020-04-10T14:52:46.044681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy fakeact tensor\n",
    "tf_fakeact = tf.convert_to_tensor(t_fakeact.detach().numpy())\n",
    "tf_real = tf.convert_to_tensor(real.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:52:46.477650Z",
     "start_time": "2020-04-10T14:52:46.464287Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_real = tf.convert_to_tensor(real.astype('float32'))\n",
    "t_real = torch.from_numpy(real.astype('float32'))\n",
    "\n",
    "if c1 is not None:\n",
    "    tf_fake_cat = tf.concat([tf_fakeact, c1_tf], axis=1)\n",
    "    tf_real_cat = tf.concat([tf_real, tf_c2], axis=1)\n",
    "    \n",
    "    t_fake_cat = torch.cat([t_fakeact, c1_t], dim=1)\n",
    "    t_real_cat = torch.cat([t_real, t_c2], dim=1)\n",
    "else:\n",
    "    tf_real_cat = tf_real\n",
    "    tf_fake_cat = tf_fake\n",
    "    \n",
    "    t_real_cat = t_real\n",
    "    t_fake_cat = t_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def cond_loss(transformer_info, data, c, m):\n",
    "    loss = []\n",
    "\n",
    "    loss = tf.zeros(tf.shape(m))\n",
    "    s = tf.shape(m)\n",
    "    print(\"init loss:\", loss)\n",
    "    #i = tf.constant(0, dtype=tf.int32)\n",
    "\n",
    "    for item in transformer_info:\n",
    "        print(item)\n",
    "        if item[4] == 0:\n",
    "        #st, ed, st_c, ed_c, is_continuous, is_softmax = item\n",
    "        #if is_continuous == 0 and is_softmax == 1:\n",
    "            data_logsoftmax = data[:, item[0]:item[1]]\n",
    "            c_argmax = tf.math.argmax(c[:, item[2]:item[3]], axis=1)\n",
    "            l = tf.reshape(tf.nn.sparse_softmax_cross_entropy_with_logits(c_argmax, data_logsoftmax), [-1, 1])\n",
    "            print(\"l:\", l)\n",
    "            print(\"loss slice:\", loss[:,:item[-1]])\n",
    "            loss = tf.concat([loss[:, :item[-1]], l, loss[:, item[-1]+1:]], axis=1)\n",
    "            print(\"loss:\", loss)\n",
    "            print()\n",
    "            #i = i + 1\n",
    "\n",
    "    #loss = tf.stack(loss, axis=1)\n",
    "    print(loss)\n",
    "    return tf.reduce_sum(loss * m) / tf.cast(tf.shape(data)[0], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 9, 0, 9, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 9, 25,  9, 25,  1], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([25, 32, 25, 32,  2], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([32, 47, 32, 47,  3], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([47, 53, 47, 53,  4], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([53, 58, 53, 58,  5], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([58, 60, 58, 60,  6], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 60, 102,  60, 102,   7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([102, 104, 102, 104,   8], dtype=int32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.cond_info_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init loss: Tensor(\"zeros:0\", shape=(500, 9), dtype=float32)\n",
      "Tensor(\"transformer_info:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_1:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_2:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_3:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_4:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_5:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_6:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_7:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"transformer_info_8:0\", shape=(5,), dtype=int32)\n",
      "l: Tensor(\"Reshape:0\", shape=(500, 1), dtype=float32)\n",
      "loss slice: Tensor(\"strided_slice_7:0\", shape=(500, None), dtype=float32)\n",
      "loss: Tensor(\"concat:0\", shape=(500, None), dtype=float32)\n",
      "\n",
      "Tensor(\"cond_8/Identity:0\", shape=(500, None), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.25683954>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ti = ti, tf.constant(9)\n",
    "cond_loss = cond_loss(transformer.cond_info_tensor(), tf_fake[1], c1_tf, m1_tf)\n",
    "cond_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tf.range(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.constant(0, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_random():\n",
    "    return tf.random.normal([10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       "array([[ 1.7181406 ,  1.257453  , -1.2608223 ,  0.66196257, -0.63675344],\n",
       "       [-0.40817076,  1.289678  , -0.34326625,  1.0015084 , -0.7475674 ],\n",
       "       [ 0.03847428,  0.5340957 , -0.49519396,  0.24867155, -0.30822927],\n",
       "       [ 0.26964048,  2.3972166 ,  0.2736266 ,  0.29006767,  1.8663241 ],\n",
       "       [-0.7362258 ,  1.5243033 , -0.97702163,  1.0311329 , -0.90981704],\n",
       "       [-1.6452307 , -2.365368  ,  0.6122781 ,  0.22597076, -1.1475091 ],\n",
       "       [ 0.50468564,  0.569523  ,  0.83959645,  0.33996007,  0.8772535 ],\n",
       "       [ 1.0880069 , -1.1181055 ,  0.12085038,  1.9761903 ,  0.6264744 ],\n",
       "       [ 0.45854285,  0.8642469 , -0.997979  ,  0.4568015 , -0.54131883],\n",
       "       [ 1.0633543 , -1.7459028 ,  0.93327826, -0.14066479, -1.8550262 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       "array([[-0.6385254 , -0.1601175 ,  0.09135835,  2.0197587 ,  0.5813612 ],\n",
       "       [-0.45433167,  0.6446218 , -1.3282415 , -1.028059  , -1.2592136 ],\n",
       "       [-0.83688265, -0.2657525 ,  1.1453569 , -1.4795412 ,  1.0295745 ],\n",
       "       [ 0.10933934, -0.32809815,  0.95528835, -0.17743436, -0.62262774],\n",
       "       [-1.5864108 ,  1.7068386 ,  0.21764839,  0.71861815, -0.9992302 ],\n",
       "       [-0.6292568 ,  0.38587192,  0.2831245 , -1.8745811 , -0.4392017 ],\n",
       "       [-0.16635115,  0.58761823,  0.24187803, -0.13324393,  1.8122779 ],\n",
       "       [ 0.5585834 , -0.8186332 , -1.3387676 ,  2.1509855 ,  1.050257  ],\n",
       "       [ 1.1381578 ,  0.48276943,  2.020263  , -0.28788325, -0.36081553],\n",
       "       [ 1.2688764 ,  0.75428027, -0.46783352, -0.45494577, -2.1779795 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
