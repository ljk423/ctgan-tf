import tensorflow as tf
import numpy as np
from unittest import TestCase

from ctgan.utils import get_test_variables
from ctgan.layers import GenActivation


class TestGenActLayer(TestCase):
    def setUp(self):
        self._vars = get_test_variables()
        self._output_tensor = [
            tf.constant([0, 1, 0], dtype=tf.int32),
            tf.constant([1, self._vars['output_dim'], 1], dtype=tf.int32)
        ]

    def tearDown(self):
        del self._vars
        del self._output_tensor

    def test_gumbel_softmax(self):
        tf.random.set_seed(0)
        inputs = tf.random.uniform(
            [self._vars['batch_size'], self._vars['input_dim']])
        gen_act_layer = GenActivation(
            self._vars['input_dim'],
            self._vars['output_dim'],
            self._output_tensor,
            self._vars['tau'])
        outputs = gen_act_layer._gumbel_softmax(inputs, tau=self._vars['tau'])
        expected_outputs = tf.constant(
            [[1.14250251e-04, 4.26296704e-03, 7.69995037e-04, 8.83099538e-10,
              8.54307073e-05, 6.01997715e-04, 6.10289317e-06, 1.99053793e-05,
              9.94139314e-01, 4.57234828e-09],
             [6.42331284e-12, 2.32214981e-04, 6.71615487e-13, 7.00047702e-12,
              9.99767840e-01, 1.66599165e-11, 2.78624571e-11, 1.70429687e-14,
              7.33631489e-11, 1.16054373e-14],
             [8.84474516e-02, 5.05535536e-05, 9.69176460e-03, 8.93279076e-01,
              1.59015326e-06, 2.80365086e-04, 1.79370927e-05, 3.15775047e-04,
              7.83375651e-03, 8.17025502e-05],
             [1.43365788e-12, 1.78363234e-14, 9.88644320e-15, 5.03437804e-17,
              1.66661745e-14, 1.61189311e-15, 2.47996780e-14, 1.00000000e+00,
              3.23347001e-14, 1.57298677e-15],
             [2.49389093e-10, 8.58996998e-07, 8.35499003e-10, 1.15500649e-08,
              2.34770007e-03, 2.58872195e-08, 9.97651279e-01, 8.88729534e-10,
              2.33092079e-09, 1.03029656e-07],
             [2.81081593e-04, 2.26601562e-03, 5.59516728e-01, 1.94648668e-01,
              9.74100381e-02, 2.28800206e-03, 1.38803601e-01, 2.60270410e-03,
              5.72434110e-05, 2.12592492e-03],
             [4.43613011e-04, 3.60679847e-10, 1.69592155e-07, 9.99393821e-01,
              2.36196535e-10, 5.77965220e-05, 9.69684406e-05, 8.07260392e-08,
              7.52342567e-06, 1.90160043e-09],
             [1.00697392e-07, 1.05936499e-02, 9.01222706e-01, 1.91847062e-06,
              3.42088957e-09, 5.32616832e-06, 1.07001495e-06, 1.21304378e-09,
              8.81751999e-02, 1.02133818e-07],
             [2.72504566e-03, 6.76886484e-05, 9.18833375e-01, 1.93336618e-03,
              2.17918847e-02, 1.16168917e-03, 4.91995476e-02, 4.44742691e-05,
              4.24227351e-03, 6.02789555e-07],
             [2.23973558e-07, 2.63323658e-03, 4.45144810e-03, 1.22458310e-08,
              1.44251687e-02, 1.15896306e-08, 4.84805042e-03, 9.73641396e-01,
              4.28421544e-07, 4.22291802e-09]],
            dtype=tf.float32)
        np.testing.assert_almost_equal(
            outputs.numpy(), expected_outputs.numpy(),
            decimal=self._vars['decimal'])

        outputs = gen_act_layer._gumbel_softmax(
            inputs, tau=self._vars['tau'], hard=True)
        expected_outputs = tf.constant(
            [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],
             [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
             [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],
             [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
             [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
             [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
             [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
             [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=tf.float32)
        np.testing.assert_almost_equal(
            outputs.numpy(), expected_outputs.numpy(),
            decimal=self._vars['decimal'])

    def test_gen_act_layer(self):
        tf.random.set_seed(0)
        inputs = tf.random.uniform(
            [self._vars['batch_size'], self._vars['input_dim']])
        gen_act_layer = GenActivation(
            self._vars['input_dim'],
            self._vars['output_dim'],
            self._output_tensor,
            self._vars['tau'])

        outputs, outputs_act = gen_act_layer(inputs)
        expected_outputs = tf.constant(
            [[0.06399402, -0.15808228, -0.11558336, 0.05494805, -0.33126852,
              -0.17637017, 0.12200963, 0.39402956, 0.32634318, -0.33070335],
             [0.25087643, -0.19576189, -0.23913635, 0.15009138, -0.3564161,
              -0.21825123, -0.14072102, 0.6937534, 0.24022676, -0.45597944],
             [0.6220621, 0.1469637, -0.18215235, 0.5548569, -0.0987303,
              0.01361492, 0.06346679, 0.3133853, 0.06415256, -0.6227628],
             [-0.10288254, -0.34491983, -0.1632171, -0.08494198, -0.4720165,
              -0.45313528, 0.10734999, 0.4955495, 0.34978482, -0.15236723],
             [0.20744193, 0.10826425, -0.32170045, 0.3576493, -0.44370794,
              0.22804666, -0.10140005, 0.2980532, -0.36202985, -0.46871606],
             [0.2961299, 0.27615362, -0.02876888, 0.39636207, -0.09771496,
              0.13101867, 0.19671272, 0.31471086, 0.11839052, -0.18321344],
             [0.71194685, -0.10758564, -0.14955036, 0.64336705, -0.34915873,
              -0.00202614, -0.26932833, 0.69632256, -0.03363119, -0.7745644],
             [0.07209513, 0.0680066, -0.678686, 0.36803997, -0.25703406,
              0.08380148, -0.12455904, 0.17812183, 0.10595389, -0.2080901],
             [0.44230077, 0.2303819, -0.3798572, 0.3656776, -0.15100443,
              0.18006304, -0.18976846, 0.5092122, 0.00852871, -0.5495614],
             [0.28090134, -0.11573267, 0.08267065, 0.24265254, -0.28548294,
              -0.32438374, -0.20357645, 0.4609607, -0.08798116, -0.3462641]],
            dtype=tf.float32)
        expected_outputs_act = tf.constant(
            [[6.39068037e-02, 1.77002791e-03, 1.25193700e-01, 1.02477856e-02,
              1.49735202e-09, 6.47506036e-04, 2.86925747e-03, 5.46443742e-04,
              1.01768979e-04, 8.58623505e-01],
             [2.45742306e-01, 5.34959540e-17, 9.24320299e-13, 2.96538376e-04,
              1.06960095e-13, 6.27823054e-12, 9.99703467e-01, 3.79032028e-10,
              1.58867346e-11, 1.05520876e-15],
             [5.52562118e-01, 1.69235438e-01, 2.19058493e-04, 7.71006227e-01,
              6.29012866e-05, 6.04885456e-04, 5.88116422e-02, 5.60584112e-07,
              5.93241093e-05, 3.99664941e-08],
             [-1.02521062e-01, 6.07741950e-03, 3.68526995e-01, 1.70489162e-04,
              3.44354689e-01, 2.34719133e-03, 2.37688962e-02, 2.18942715e-03,
              2.52468139e-01, 9.67699089e-05],
             [2.04516679e-01, 1.54426634e-12, 1.00000000e+00, 1.35123542e-12,
              5.70916944e-14, 9.43794847e-13, 4.91985480e-11, 3.00242470e-12,
              2.79367024e-13, 3.27231109e-09],
             [2.87766963e-01, 6.21765039e-08, 9.99999762e-01, 4.72602180e-10,
              1.24590296e-10, 5.15050269e-09, 1.51030549e-10, 2.43091325e-08,
              3.34285346e-08, 7.06010326e-08],
             [6.11896217e-01, 8.75775469e-04, 6.54194446e-05, 5.68488955e-01,
              1.58259791e-05, 9.76431238e-06, 1.09536675e-04, 4.30433631e-01,
              1.16056240e-08, 1.02890465e-06],
             [7.19704702e-02, 9.99824107e-01, 2.56632150e-12, 7.05259590e-05,
              1.86619513e-06, 1.53097403e-07, 1.07311034e-05, 1.69422953e-09,
              1.07538920e-08, 9.26654611e-05],
             [4.15549695e-01, 8.13624501e-01, 1.05664050e-07, 4.52118712e-07,
              1.65237780e-05, 2.12310370e-05, 8.44316972e-09, 1.86334923e-01,
              1.00243994e-06, 1.15290266e-06],
             [2.73739070e-01, 4.40242875e-05, 9.46386695e-01, 7.57793710e-03,
              6.23768428e-03, 4.14400222e-03, 2.07485538e-02, 8.01620726e-03,
              6.84069842e-03, 4.06040726e-06]],
            dtype=tf.float32)

        np.testing.assert_almost_equal(
            outputs.numpy(), expected_outputs.numpy(),
            decimal=self._vars['decimal'])
        np.testing.assert_almost_equal(
            outputs_act.numpy(), expected_outputs_act.numpy(),
            decimal=self._vars['decimal'])
